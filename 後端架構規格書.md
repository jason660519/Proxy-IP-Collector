# Proxy IP Pool Collector - 後端架構規格書

## 1. 架構概述

### 1.1 設計理念
後端架構採用微服務架構設計，實現高可用性、高擴展性和高性能的代理IP池管理系統。通過模組化設計和服務解耦，支持水平擴展和故障隔離。

### 1.2 技術選型
- **後端框架**: FastAPI (Python 3.11+)
- **數據庫**: PostgreSQL 15 (主數據庫) + Redis 7 (緩存)
- **消息隊列**: RabbitMQ (異步任務處理)
- **容器化**: Docker + Docker Compose
- **API文檔**: OpenAPI 3.0 + Swagger UI
- **測試框架**: pytest + httpx + pytest-asyncio
- **代碼質量**: black + isort + mypy + flake8
- **監控**: Prometheus + Grafana + Sentry

## 2. 系統架構設計

### 2.1 整體架構圖
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Load Balancer │    │   API Gateway   │    │   Web Frontend  │
│    (Nginx)      │────│   (Kong/Traefik) │────│   (React)       │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                        │                        │
         │                        │                        │
         ▼                        ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│  Proxy Service  │    │  ETL Service    │    │ Monitor Service │
│   (FastAPI)     │────│   (Celery)      │────│  (Prometheus)   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                        │                        │
         │                        │                        │
         ▼                        ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│  PostgreSQL     │    │     Redis       │    │   RabbitMQ      │
│   (主數據庫)     │────│   (緩存/會話)    │────│  (消息隊列)      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 2.2 服務拆分
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api.v1.router import api_router
from app.core.config import settings
from app.core.database import init_db
from app.core.logging import setup_logging

app = FastAPI(
    title="Proxy IP Pool Collector API",
    description="代理IP池收集器後端API服務",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# 配置CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_HOSTS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 設置日誌
setup_logging()

# 初始化數據庫
@app.on_event("startup")
async def startup_event():
    await init_db()

# 註冊路由
app.include_router(api_router, prefix="/api/v1")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## 3. 數據模型設計

### 3.1 核心實體模型
```python
# app/models/proxy.py
from datetime import datetime
from typing import Optional, Dict, Any
from sqlalchemy import Column, String, Integer, Float, DateTime, Boolean, JSON, Index
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.ext.declarative import declarative_base
import uuid

Base = declarative_base()

class Proxy(Base):
    """代理IP實體模型"""
    __tablename__ = "proxies"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    ip = Column(String(45), nullable=False, index=True, comment="IP地址")
    port = Column(Integer, nullable=False, comment="端口號")
    protocol = Column(String(10), nullable=False, index=True, comment="協議類型")
    country = Column(String(2), index=True, comment="國家代碼")
    anonymity = Column(String(20), index=True, comment="匿名等級")
    status = Column(String(20), default="inactive", index=True, comment="狀態")
    response_time = Column(Integer, default=0, comment="響應時間(ms)")
    success_rate = Column(Float, default=0.0, comment="成功率")
    last_checked = Column(DateTime, default=datetime.utcnow, comment="最後檢查時間")
    last_success = Column(DateTime, comment="最後成功時間")
    source = Column(String(100), comment="來源")
    quality_score = Column(Float, default=0.0, comment="質量評分")
    metadata = Column(JSON, default=dict, comment="額外元數據")
    is_active = Column(Boolean, default=True, index=True, comment="是否啟用")
    created_at = Column(DateTime, default=datetime.utcnow, comment="創建時間")
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, comment="更新時間")
    
    # 複合索引
    __table_args__ = (
        Index('idx_proxy_ip_port', 'ip', 'port', unique=True),
        Index('idx_proxy_status_protocol', 'status', 'protocol'),
        Index('idx_proxy_quality_score', 'quality_score'),
        Index('idx_proxy_last_checked', 'last_checked'),
    )

class ProxySource(Base):
    """代理來源配置"""
    __tablename__ = "proxy_sources"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    name = Column(String(100), unique=True, nullable=False, comment="來源名稱")
    source_type = Column(String(50), nullable=False, comment="來源類型")
    config = Column(JSON, default=dict, comment="來源配置")
    is_active = Column(Boolean, default=True, comment="是否啟用")
    priority = Column(Integer, default=1, comment="優先級")
    last_crawl = Column(DateTime, comment="最後爬取時間")
    crawl_interval = Column(Integer, default=3600, comment="爬取間隔(秒)")
    success_rate = Column(Float, default=0.0, comment="成功率")
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

class ProxyCheckResult(Base):
    """代理檢查結果"""
    __tablename__ = "proxy_check_results"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    proxy_id = Column(UUID(as_uuid=True), nullable=False, index=True)
    is_successful = Column(Boolean, nullable=False, comment="是否成功")
    response_time = Column(Integer, comment="響應時間")
    error_message = Column(String(500), comment="錯誤信息")
    check_type = Column(String(50), comment="檢查類型")
    target_url = Column(String(500), comment="目標URL")
    headers_sent = Column(JSON, default=dict, comment="發送的請求頭")
    headers_received = Column(JSON, default=dict, comment="接收的響應頭")
    status_code = Column(Integer, comment="HTTP狀態碼")
    checked_at = Column(DateTime, default=datetime.utcnow, index=True, comment="檢查時間")
    
    __table_args__ = (
        Index('idx_check_result_proxy_time', 'proxy_id', 'checked_at'),
        Index('idx_check_result_success', 'is_successful', 'checked_at'),
    )

class ETLTask(Base):
    """ETL任務記錄"""
    __tablename__ = "etl_tasks"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    task_type = Column(String(50), nullable=False, index=True, comment="任務類型")
    status = Column(String(20), default="pending", index=True, comment="任務狀態")
    parameters = Column(JSON, default=dict, comment="任務參數")
    result = Column(JSON, default=dict, comment="執行結果")
    error_message = Column(String(1000), comment="錯誤信息")
    started_at = Column(DateTime, comment="開始時間")
    completed_at = Column(DateTime, comment="完成時間")
    duration = Column(Integer, comment="執行時長(秒)")
    created_by = Column(String(100), comment="創建者")
    created_at = Column(DateTime, default=datetime.utcnow)
    
    __table_args__ = (
        Index('idx_etl_task_status_type', 'status', 'task_type'),
        Index('idx_etl_task_created', 'created_at'),
    )
```

### 3.2 Pydantic模型
```python
# app/schemas/proxy.py
from datetime import datetime
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field, validator
from enum import Enum

class Protocol(str, Enum):
    HTTP = "http"
    HTTPS = "https"
    SOCKS4 = "socks4"
    SOCKS5 = "socks5"

class Anonymity(str, Enum):
    TRANSPARENT = "transparent"
    ANONYMOUS = "anonymous"
    ELITE = "elite"

class ProxyStatus(str, Enum):
    ACTIVE = "active"
    INACTIVE = "inactive"
    CHECKING = "checking"
    FAILED = "failed"

class ProxyBase(BaseModel):
    ip: str = Field(..., description="IP地址", example="192.168.1.1")
    port: int = Field(..., ge=1, le=65535, description="端口號", example=8080)
    protocol: Protocol = Field(..., description="協議類型")
    country: Optional[str] = Field(None, max_length=2, description="國家代碼")
    anonymity: Optional[Anonymity] = Field(None, description="匿名等級")
    source: Optional[str] = Field(None, max_length=100, description="來源")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="額外元數據")

    @validator('ip')
    def validate_ip(cls, v):
        import ipaddress
        try:
            ipaddress.ip_address(v)
            return v
        except ValueError:
            raise ValueError('Invalid IP address format')

class ProxyCreate(ProxyBase):
    pass

class ProxyUpdate(BaseModel):
    protocol: Optional[Protocol] = None
    country: Optional[str] = None
    anonymity: Optional[Anonymity] = None
    status: Optional[ProxyStatus] = None
    response_time: Optional[int] = Field(None, ge=0, description="響應時間(ms)")
    success_rate: Optional[float] = Field(None, ge=0.0, le=1.0, description="成功率")
    source: Optional[str] = None
    quality_score: Optional[float] = Field(None, ge=0.0, le=1.0, description="質量評分")
    is_active: Optional[bool] = None

class ProxyInDB(ProxyBase):
    id: str
    status: ProxyStatus
    response_time: int
    success_rate: float
    last_checked: datetime
    last_success: Optional[datetime]
    quality_score: float
    is_active: bool
    created_at: datetime
    updated_at: datetime

    class Config:
        orm_mode = True

class ProxyList(BaseModel):
    proxies: List[ProxyInDB]
    total: int
    page: int
    page_size: int
    total_pages: int

class ProxyFilter(BaseModel):
    protocol: Optional[List[Protocol]] = None
    country: Optional[List[str]] = None
    anonymity: Optional[List[Anonymity]] = None
    status: Optional[List[ProxyStatus]] = None
    min_quality_score: Optional[float] = Field(None, ge=0.0, le=1.0)
    max_response_time: Optional[int] = Field(None, ge=0)
    search_text: Optional[str] = None
    is_active: Optional[bool] = None
    source: Optional[List[str]] = None

class ProxyStats(BaseModel):
    total_proxies: int
    active_proxies: int
    by_protocol: Dict[str, int]
    by_country: Dict[str, int]
    by_anonymity: Dict[str, int]
    average_response_time: float
    average_success_rate: float
```

## 4. API接口設計

### 4.1 代理管理API
```python
# app/api/v1/endpoints/proxies.py
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query, status
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.database import get_db
from app.schemas.proxy import ProxyInDB, ProxyCreate, ProxyUpdate, ProxyList, ProxyFilter, ProxyStats
from app.services.proxy_service import ProxyService
from app.core.security import get_current_user
from app.models.user import User

router = APIRouter(prefix="/proxies", tags=["proxies"])

@router.get("/", response_model=ProxyList)
async def get_proxies(
    page: int = Query(1, ge=1, description="頁碼"),
    page_size: int = Query(20, ge=1, le=100, description="每頁數量"),
    filter: Optional[ProxyFilter] = None,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取代理列表"""
    service = ProxyService(db)
    result = await service.get_proxies(page, page_size, filter)
    return result

@router.get("/{proxy_id}", response_model=ProxyInDB)
async def get_proxy(
    proxy_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取單個代理詳情"""
    service = ProxyService(db)
    proxy = await service.get_proxy_by_id(proxy_id)
    if not proxy:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proxy not found"
        )
    return proxy

@router.post("/", response_model=ProxyInDB, status_code=status.HTTP_201_CREATED)
async def create_proxy(
    proxy: ProxyCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """創建新代理"""
    service = ProxyService(db)
    return await service.create_proxy(proxy)

@router.put("/{proxy_id}", response_model=ProxyInDB)
async def update_proxy(
    proxy_id: str,
    proxy_update: ProxyUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """更新代理信息"""
    service = ProxyService(db)
    proxy = await service.update_proxy(proxy_id, proxy_update)
    if not proxy:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proxy not found"
        )
    return proxy

@router.delete("/{proxy_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_proxy(
    proxy_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """刪除代理"""
    service = ProxyService(db)
    success = await service.delete_proxy(proxy_id)
    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proxy not found"
        )

@router.post("/{proxy_id}/check")
async def check_proxy(
    proxy_id: str,
    target_url: Optional[str] = Query(None, description="檢查目標URL"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """檢查代理可用性"""
    service = ProxyService(db)
    result = await service.check_proxy(proxy_id, target_url)
    return result

@router.post("/bulk-check")
async def bulk_check_proxies(
    proxy_ids: List[str],
    target_url: Optional[str] = Query(None, description="檢查目標URL"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """批量檢查代理"""
    service = ProxyService(db)
    results = await service.bulk_check_proxies(proxy_ids, target_url)
    return {"results": results}

@router.post("/bulk-delete")
async def bulk_delete_proxies(
    proxy_ids: List[str],
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """批量刪除代理"""
    service = ProxyService(db)
    deleted_count = await service.bulk_delete_proxies(proxy_ids)
    return {"deleted_count": deleted_count}

@router.get("/stats", response_model=ProxyStats)
async def get_proxy_stats(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取代理統計信息"""
    service = ProxyService(db)
    stats = await service.get_proxy_stats()
    return stats

@router.get("/history")
async def get_proxy_history(
    time_range: str = Query("24h", regex="^(1h|24h|7d|30d)$", description="時間範圍"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取代理歷史數據"""
    service = ProxyService(db)
    history = await service.get_proxy_history(time_range)
    return history
```

### 4.2 ETL任務API
```python
# app/api/v1/endpoints/etl.py
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException, Query, status
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.database import get_db
from app.schemas.etl import ETLTaskCreate, ETLTaskInDB, ETLTaskList
from app.services.etl_service import ETLService
from app.core.security import get_current_user
from app.models.user import User

router = APIRouter(prefix="/etl", tags=["etl"])

@router.post("/tasks", response_model=ETLTaskInDB, status_code=status.HTTP_201_CREATED)
async def create_etl_task(
    task: ETLTaskCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """創建ETL任務"""
    service = ETLService(db)
    return await service.create_task(task, current_user.id)

@router.get("/tasks/{task_id}", response_model=ETLTaskInDB)
async def get_etl_task(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取ETL任務詳情"""
    service = ETLService(db)
    task = await service.get_task_by_id(task_id)
    if not task:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Task not found"
        )
    return task

@router.get("/tasks", response_model=ETLTaskList)
async def get_etl_tasks(
    page: int = Query(1, ge=1, description="頁碼"),
    page_size: int = Query(20, ge=1, le=100, description="每頁數量"),
    status: Optional[str] = Query(None, description="任務狀態"),
    task_type: Optional[str] = Query(None, description="任務類型"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """獲取ETL任務列表"""
    service = ETLService(db)
    result = await service.get_tasks(page, page_size, status, task_type)
    return result

@router.post("/tasks/{task_id}/cancel")
async def cancel_etl_task(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """取消ETL任務"""
    service = ETLService(db)
    success = await service.cancel_task(task_id)
    if not success:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Cannot cancel task"
        )
    return {"message": "Task cancelled successfully"}
```

## 5. 業務邏輯層

### 5.1 代理服務
```python
# app/services/proxy_service.py
from typing import List, Optional, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, func, text
from datetime import datetime, timedelta
from app.models.proxy import Proxy, ProxyCheckResult
from app.schemas.proxy import ProxyCreate, ProxyUpdate, ProxyFilter, ProxyInDB
from app.core.exceptions import BusinessException
from app.services.proxy_checker import ProxyChecker
from app.utils.cache import cache_manager
import asyncio

class ProxyService:
    def __init__(self, db: AsyncSession):
        self.db = db
        self.checker = ProxyChecker()

    async def get_proxies(
        self, 
        page: int, 
        page_size: int, 
        filter: Optional[ProxyFilter] = None
    ) -> Dict[str, Any]:
        """獲取代理列表"""
        # 構建查詢條件
        query = select(Proxy).where(Proxy.is_active == True)
        
        if filter:
            conditions = []
            if filter.protocol:
                conditions.append(Proxy.protocol.in_(filter.protocol))
            if filter.country:
                conditions.append(Proxy.country.in_(filter.country))
            if filter.anonymity:
                conditions.append(Proxy.anonymity.in_(filter.anonymity))
            if filter.status:
                conditions.append(Proxy.status.in_(filter.status))
            if filter.min_quality_score is not None:
                conditions.append(Proxy.quality_score >= filter.min_quality_score)
            if filter.max_response_time is not None:
                conditions.append(Proxy.response_time <= filter.max_response_time)
            if filter.search_text:
                conditions.append(
                    or_(
                        Proxy.ip.contains(filter.search_text),
                        Proxy.source.contains(filter.search_text)
                    )
                )
            if filter.is_active is not None:
                conditions.append(Proxy.is_active == filter.is_active)
            
            if conditions:
                query = query.where(and_(*conditions))
        
        # 計算總數
        count_query = select(func.count()).select_from(query.subquery())
        total = await self.db.execute(count_query)
        total_count = total.scalar()
        
        # 分頁查詢
        offset = (page - 1) * page_size
        query = query.offset(offset).limit(page_size)
        
        result = await self.db.execute(query)
        proxies = result.scalars().all()
        
        return {
            "proxies": [ProxyInDB.from_orm(proxy) for proxy in proxies],
            "total": total_count,
            "page": page,
            "page_size": page_size,
            "total_pages": (total_count + page_size - 1) // page_size
        }

    async def get_proxy_by_id(self, proxy_id: str) -> Optional[ProxyInDB]:
        """根據ID獲取代理"""
        result = await self.db.execute(
            select(Proxy).where(Proxy.id == proxy_id, Proxy.is_active == True)
        )
        proxy = result.scalar_one_or_none()
        return ProxyInDB.from_orm(proxy) if proxy else None

    async def create_proxy(self, proxy_create: ProxyCreate) -> ProxyInDB:
        """創建新代理"""
        # 檢查是否已存在
        existing = await self.db.execute(
            select(Proxy).where(
                Proxy.ip == proxy_create.ip,
                Proxy.port == proxy_create.port
            )
        )
        if existing.scalar_one_or_none():
            raise BusinessException("Proxy already exists")
        
        # 創建代理
        proxy = Proxy(**proxy_create.dict())
        self.db.add(proxy)
        await self.db.commit()
        await self.db.refresh(proxy)
        
        return ProxyInDB.from_orm(proxy)

    async def update_proxy(
        self, 
        proxy_id: str, 
        proxy_update: ProxyUpdate
    ) -> Optional[ProxyInDB]:
        """更新代理信息"""
        result = await self.db.execute(
            select(Proxy).where(Proxy.id == proxy_id)
        )
        proxy = result.scalar_one_or_none()
        
        if not proxy:
            return None
        
        # 更新字段
        update_data = proxy_update.dict(exclude_unset=True)
        for field, value in update_data.items():
            setattr(proxy, field, value)
        
        proxy.updated_at = datetime.utcnow()
        await self.db.commit()
        await self.db.refresh(proxy)
        
        # 清除緩存
        await cache_manager.delete_pattern(f"proxy:*:{proxy_id}")
        
        return ProxyInDB.from_orm(proxy)

    async def delete_proxy(self, proxy_id: str) -> bool:
        """刪除代理"""
        result = await self.db.execute(
            select(Proxy).where(Proxy.id == proxy_id)
        )
        proxy = result.scalar_one_or_none()
        
        if not proxy:
            return False
        
        proxy.is_active = False
        await self.db.commit()
        
        # 清除緩存
        await cache_manager.delete_pattern(f"proxy:*:{proxy_id}")
        
        return True

    async def check_proxy(
        self, 
        proxy_id: str, 
        target_url: Optional[str] = None
    ) -> Dict[str, Any]:
        """檢查代理可用性"""
        # 獲取代理信息
        result = await self.db.execute(
            select(Proxy).where(Proxy.id == proxy_id, Proxy.is_active == True)
        )
        proxy = result.scalar_one_or_none()
        
        if not proxy:
            raise BusinessException("Proxy not found or inactive")
        
        # 執行檢查
        check_result = await self.checker.check_proxy(
            proxy.ip, proxy.port, proxy.protocol, target_url
        )
        
        # 更新代理狀態
        proxy.status = "active" if check_result["success"] else "inactive"
        proxy.response_time = check_result.get("response_time", 0)
        proxy.last_checked = datetime.utcnow()
        
        if check_result["success"]:
            proxy.last_success = datetime.utcnow()
        
        # 記錄檢查結果
        check_record = ProxyCheckResult(
            proxy_id=proxy_id,
            is_successful=check_result["success"],
            response_time=check_result.get("response_time"),
            error_message=check_result.get("error_message"),
            check_type="manual",
            target_url=target_url,
            status_code=check_result.get("status_code"),
            headers_sent=check_result.get("request_headers", {}),
            headers_received=check_result.get("response_headers", {})
        )
        
        self.db.add(check_record)
        await self.db.commit()
        await self.db.refresh(proxy)
        
        # 更新成功率
        await self._update_proxy_success_rate(proxy_id)
        
        return check_result

    async def bulk_check_proxies(
        self, 
        proxy_ids: List[str], 
        target_url: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """批量檢查代理"""
        # 並發檢查
        tasks = [
            self.check_proxy(proxy_id, target_url) 
            for proxy_id in proxy_ids
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 處理結果
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "proxy_id": proxy_ids[i],
                    "success": False,
                    "error": str(result)
                })
            else:
                processed_results.append({
                    "proxy_id": proxy_ids[i],
                    **result
                })
        
        return processed_results

    async def get_proxy_stats(self) -> Dict[str, Any]:
        """獲取代理統計信息"""
        # 檢查緩存
        cache_key = "proxy:stats"
        cached_stats = await cache_manager.get(cache_key)
        if cached_stats:
            return cached_stats
        
        # 統計查詢
        total_query = select(func.count()).select_from(Proxy).where(Proxy.is_active == True)
        total_result = await self.db.execute(total_query)
        total_count = total_result.scalar()
        
        active_query = select(func.count()).select_from(Proxy).where(
            Proxy.is_active == True,
            Proxy.status == "active"
        )
        active_result = await self.db.execute(active_query)
        active_count = active_result.scalar()
        
        # 按協議統計
        protocol_query = select(
            Proxy.protocol,
            func.count(Proxy.id)
        ).where(Proxy.is_active == True).group_by(Proxy.protocol)
        protocol_result = await self.db.execute(protocol_query)
        protocol_stats = dict(protocol_result.all())
        
        # 按國家統計
        country_query = select(
            Proxy.country,
            func.count(Proxy.id)
        ).where(Proxy.is_active == True).group_by(Proxy.country)
        country_result = await self.db.execute(country_query)
        country_stats = dict(country_result.all())
        
        # 按匿名等級統計
        anonymity_query = select(
            Proxy.anonymity,
            func.count(Proxy.id)
        ).where(Proxy.is_active == True).group_by(Proxy.anonymity)
        anonymity_result = await self.db.execute(anonymity_query)
        anonymity_stats = dict(anonymity_result.all())
        
        # 平均響應時間
        avg_response_query = select(func.avg(Proxy.response_time)).where(
            Proxy.is_active == True,
            Proxy.status == "active"
        )
        avg_response_result = await self.db.execute(avg_response_query)
        avg_response_time = float(avg_response_result.scalar() or 0)
        
        # 平均成功率
        avg_success_query = select(func.avg(Proxy.success_rate)).where(
            Proxy.is_active == True,
            Proxy.status == "active"
        )
        avg_success_result = await self.db.execute(avg_success_query)
        avg_success_rate = float(avg_success_result.scalar() or 0)
        
        stats = {
            "total_proxies": total_count,
            "active_proxies": active_count,
            "by_protocol": protocol_stats,
            "by_country": country_stats,
            "by_anonymity": anonymity_stats,
            "average_response_time": avg_response_time,
            "average_success_rate": avg_success_rate
        }
        
        # 緩存5分鐘
        await cache_manager.set(cache_key, stats, expire=300)
        
        return stats

    async def _update_proxy_success_rate(self, proxy_id: str) -> None:
        """更新代理成功率"""
        # 獲取最近30天的檢查記錄
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        
        result = await self.db.execute(
            select(
                func.count(ProxyCheckResult.id),
                func.sum(func.cast(ProxyCheckResult.is_successful, Integer))
            ).where(
                ProxyCheckResult.proxy_id == proxy_id,
                ProxyCheckResult.checked_at >= thirty_days_ago
            )
        )
        
        total_checks, successful_checks = result.one()
        
        if total_checks > 0:
            success_rate = successful_checks / total_checks
            
            # 更新代理成功率
            await self.db.execute(
                select(Proxy).where(Proxy.id == proxy_id)
            )
            proxy = (await self.db.execute(select(Proxy).where(Proxy.id == proxy_id))).scalar_one()
            proxy.success_rate = success_rate
            
            # 更新質量評分
            quality_score = await self._calculate_quality_score(proxy)
            proxy.quality_score = quality_score
            
            await self.db.commit()

    async def _calculate_quality_score(self, proxy: Proxy) -> float:
        """計算代理質量評分"""
        score = 0.0
        
        # 成功率權重 (40%)
        score += proxy.success_rate * 0.4
        
        # 響應時間權重 (30%)
        if proxy.response_time > 0:
            # 響應時間越短得分越高 (假設最佳響應時間為100ms)
            response_score = max(0, 1 - (proxy.response_time / 5000))
            score += response_score * 0.3
        
        # 穩定性權重 (20%)
        # 基於最近檢查時間
        if proxy.last_success:
            days_since_success = (datetime.utcnow() - proxy.last_success).days
            stability_score = max(0, 1 - (days_since_success / 7))
            score += stability_score * 0.2
        
        # 匿名等級權重 (10%)
        anonymity_scores = {
            "elite": 1.0,
            "anonymous": 0.8,
            "transparent": 0.6,
            None: 0.5
        }
        score += anonymity_scores.get(proxy.anonymity, 0.5) * 0.1
        
        return round(score, 2)
```

### 5.2 代理檢查服務
```python
# app/services/proxy_checker.py
import asyncio
import aiohttp
import time
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse
import logging

logger = logging.getLogger(__name__)

class ProxyChecker:
    def __init__(self):
        self.timeout = 30
        self.max_redirects = 5
        self.user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        
        # 檢查目標URL列表
        self.check_targets = [
            "http://httpbin.org/ip",
            "https://httpbin.org/ip",
            "http://icanhazip.com",
            "https://api.ipify.org?format=json"
        ]

    async def check_proxy(
        self, 
        ip: str, 
        port: int, 
        protocol: str, 
        target_url: Optional[str] = None
    ) -> Dict[str, Any]:
        """檢查單個代理"""
        start_time = time.time()
        
        try:
            # 構建代理URL
            proxy_url = f"{protocol}://{ip}:{port}"
            
            # 選擇檢查目標
            check_url = target_url or self._select_check_target(protocol)
            
            # 配置連接器
            connector = aiohttp.TCPConnector(
                limit=1,
                limit_per_host=1,
                ttl_dns_cache=300,
                use_dns_cache=True,
                ssl=False if protocol in ["http", "socks4"] else True
            )
            
            # 配置超時
            timeout = aiohttp.ClientTimeout(
                total=self.timeout,
                connect=10,
                sock_read=20
            )
            
            # 創建會話
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={"User-Agent": self.user_agent}
            ) as session:
                
                # 配置代理
                if protocol in ["socks4", "socks5"]:
                    # SOCKS代理需要特殊處理
                    proxy_connector = self._create_socks_connector(protocol, ip, port)
                    session._connector = proxy_connector
                else:
                    session._proxy = proxy_url
                
                # 發送請求
                request_start = time.time()
                async with session.get(check_url, allow_redirects=True) as response:
                    response_text = await response.text()
                    request_time = (time.time() - request_start) * 1000  # 轉換為毫秒
                    
                    # 分析響應
                    anonymity_level = self._analyze_anonymity(response, response_text, ip)
                    
                    result = {
                        "success": True,
                        "response_time": int(request_time),
                        "status_code": response.status,
                        "anonymity": anonymity_level,
                        "response_headers": dict(response.headers),
                        "response_size": len(response_text),
                        "error_message": None
                    }
                    
                    logger.info(f"Proxy check successful: {ip}:{port} - {request_time:.0f}ms")
                    return result
                    
        except asyncio.TimeoutError:
            error_msg = "Connection timeout"
            logger.warning(f"Proxy check timeout: {ip}:{port}")
        except aiohttp.ClientProxyConnectionError:
            error_msg = "Proxy connection failed"
            logger.warning(f"Proxy connection failed: {ip}:{port}")
        except aiohttp.ClientError as e:
            error_msg = f"Client error: {str(e)}"
            logger.warning(f"Proxy check client error: {ip}:{port} - {error_msg}")
        except Exception as e:
            error_msg = f"Unexpected error: {str(e)}"
            logger.error(f"Proxy check unexpected error: {ip}:{port} - {error_msg}")
        
        # 失敗結果
        request_time = (time.time() - start_time) * 1000
        return {
            "success": False,
            "response_time": int(request_time),
            "status_code": None,
            "anonymity": None,
            "response_headers": {},
            "response_size": 0,
            "error_message": error_msg
        }

    async def bulk_check_proxies(
        self, 
        proxies: List[Dict[str, Any]], 
        max_concurrent: int = 50,
        target_url: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """批量檢查代理"""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def check_single_proxy(proxy_info: Dict[str, Any]) -> Dict[str, Any]:
            async with semaphore:
                result = await self.check_proxy(
                    proxy_info["ip"],
                    proxy_info["port"],
                    proxy_info["protocol"],
                    target_url
                )
                return {
                    "proxy_id": proxy_info.get("id"),
                    **result
                }
        
        # 創建檢查任務
        tasks = [check_single_proxy(proxy) for proxy in proxies]
        
        # 執行批量檢查
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 處理異常結果
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "proxy_id": proxies[i].get("id"),
                    "success": False,
                    "error": str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results

    def _select_check_target(self, protocol: str) -> str:
        """選擇合適的檢查目標"""
        if protocol == "https":
            # 對於HTTPS代理，優先使用HTTPS目標
            https_targets = [url for url in self.check_targets if url.startswith("https://")]
            return https_targets[0] if https_targets else self.check_targets[0]
        else:
            # 對於HTTP代理，可以使用任何目標
            return self.check_targets[0]

    def _create_socks_connector(self, protocol: str, ip: str, port: int):
        """創建SOCKS連接器"""
        try:
            import aiohttp_socks
            
            if protocol == "socks4":
                proxy_type = aiohttp_socks.ProxyType.SOCKS4
            else:  # socks5
                proxy_type = aiohttp_socks.ProxyType.SOCKS5
            
            return aiohttp_socks.ProxyConnector(
                proxy_type=proxy_type,
                host=ip,
                port=port,
                limit=1,
                limit_per_host=1
            )
        except ImportError:
            logger.error("aiohttp-socks not installed, cannot check SOCKS proxies")
            raise RuntimeError("SOCKS proxy support not available")

    def _analyze_anonymity(
        self, 
        response: aiohttp.ClientResponse, 
        response_text: str, 
        original_ip: str
    ) -> str:
        """分析代理匿名等級"""
        # 檢查響應頭中是否包含原始IP
        headers_str = str(response.headers).lower()
        if original_ip in headers_str:
            return "transparent"
        
        # 檢查響應內容中是否包含原始IP
        if original_ip in response_text.lower():
            return "transparent"
        
        # 檢查常見的代理頭部
        proxy_headers = [
            "x-forwarded-for", "x-real-ip", "via", "x-proxy-id",
            "x-forwarded", "forwarded-for", "forwarded"
        ]
        
        for header in proxy_headers:
            if header in headers_str:
                return "anonymous"
        
        # 如果都沒有發現，則認為是高度匿名
        return "elite"
```

## 6. 異步任務處理

### 6.1 Celery配置
```python
# app/core/celery.py
from celery import Celery
from app.core.config import settings

celery_app = Celery(
    "proxy_collector",
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND,
    include=["app.tasks.proxy_tasks", "app.tasks.etl_tasks"]
)

celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,
    task_track_started=True,
    task_time_limit=30 * 60,  # 30分鐘
    task_soft_time_limit=25 * 60,  # 25分鐘
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=1000,
)

# 定時任務配置
celery_app.conf.beat_schedule = {
    "crawl-free-proxies": {
        "task": "app.tasks.proxy_tasks.crawl_free_proxies",
        "schedule": 3600.0,  # 每小時
    },
    "check-inactive-proxies": {
        "task": "app.tasks.proxy_tasks.check_inactive_proxies",
        "schedule": 1800.0,  # 每30分鐘
    },
    "update-proxy-stats": {
        "task": "app.tasks.proxy_tasks.update_proxy_stats",
        "schedule": 300.0,  # 每5分鐘
    },
    "cleanup-old-data": {
        "task": "app.tasks.etl_tasks.cleanup_old_data",
        "schedule": 86400.0,  # 每天
    },
}
```

### 6.2 代理任務
```python
# app/tasks/proxy_tasks.py
from celery import Task
from app.core.celery import celery_app
from app.core.database import AsyncSessionLocal
from app.services.proxy_service import ProxyService
from app.services.proxy_collector import ProxyCollector
from app.core.logging import get_task_logger
from datetime import datetime, timedelta
import asyncio

logger = get_task_logger(__name__)

class ProxyTask(Task):
    """代理任務基類"""
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        logger.error(f"Task {task_id} failed: {exc}")
        super().on_failure(exc, task_id, args, kwargs, einfo)

@celery_app.task(base=ProxyTask, bind=True)
def crawl_free_proxies(self):
    """爬取免費代理"""
    logger.info("Starting free proxy crawling task")
    
    async def _crawl():
        async with AsyncSessionLocal() as db:
            collector = ProxyCollector(db)
            try:
                result = await collector.crawl_free_proxies()
                logger.info(f"Crawled {result['total_proxies']} proxies from {result['sources']} sources")
                return result
            except Exception as e:
                logger.error(f"Crawl task failed: {e}")
                raise
    
    return asyncio.run(_crawl())

@celery_app.task(base=ProxyTask, bind=True)
def check_inactive_proxies(self):
    """檢查非活躍代理"""
    logger.info("Starting inactive proxy checking task")
    
    async def _check():
        async with AsyncSessionLocal() as db:
            service = ProxyService(db)
            try:
                # 獲取需要檢查的代理
                result = await service.get_proxies(
                    page=1,
                    page_size=100,
                    filter={"status": ["inactive", "failed"]}
                )
                
                if not result["proxies"]:
                    logger.info("No inactive proxies to check")
                    return {"checked": 0, "reactivated": 0}
                
                # 批量檢查
                proxy_ids = [proxy.id for proxy in result["proxies"]]
                check_results = await service.bulk_check_proxies(proxy_ids)
                
                # 統計結果
                reactivated = sum(1 for r in check_results if r.get("success", False))
                
                logger.info(f"Checked {len(check_results)} inactive proxies, {reactivated} reactivated")
                
                return {
                    "checked": len(check_results),
                    "reactivated": reactivated
                }
                
            except Exception as e:
                logger.error(f"Check inactive task failed: {e}")
                raise
    
    return asyncio.run(_check())

@celery_app.task(base=ProxyTask, bind=True)
def update_proxy_stats(self):
    """更新代理統計信息"""
    logger.info("Starting proxy stats update task")
    
    async def _update():
        async with AsyncSessionLocal() as db:
            service = ProxyService(db)
            try:
                stats = await service.get_proxy_stats()
                logger.info(f"Updated proxy stats: {stats}")
                return stats
            except Exception as e:
                logger.error(f"Stats update task failed: {e}")
                raise
    
    return asyncio.run(_update())

@celery_app.task(base=ProxyTask, bind=True)
def validate_proxy_quality(self, proxy_ids: List[str]):
    """驗證代理質量"""
    logger.info(f"Starting quality validation for {len(proxy_ids)} proxies")
    
    async def _validate():
        async with AsyncSessionLocal() as db:
            service = ProxyService(db)
            try:
                # 使用多個目標進行檢查
                test_urls = [
                    "http://httpbin.org/ip",
                    "https://httpbin.org/user-agent",
                    "http://icanhazip.com"
                ]
                
                results = []
                for proxy_id in proxy_ids:
                    proxy_results = []
                    for url in test_urls:
                        result = await service.check_proxy(proxy_id, url)
                        proxy_results.append(result)
                    
                    # 計算綜合評分
                    success_count = sum(1 for r in proxy_results if r["success"])
                    avg_response_time = sum(r.get("response_time", 0) for r in proxy_results) / len(proxy_results)
                    
                    results.append({
                        "proxy_id": proxy_id,
                        "success_rate": success_count / len(test_urls),
                        "average_response_time": avg_response_time,
                        "details": proxy_results
                    })
                
                logger.info(f"Validated {len(results)} proxies")
                return results
                
            except Exception as e:
                logger.error(f"Quality validation task failed: {e}")
                raise
    
    return asyncio.run(_validate())
```

## 7. 配置管理

### 7.1 配置類
```python
# app/core/config.py
from pydantic import BaseSettings, validator
from typing import List, Optional
import os

class Settings(BaseSettings):
    # 應用配置
    APP_NAME: str = "Proxy IP Pool Collector"
    APP_VERSION: str = "1.0.0"
    DEBUG: bool = False
    
    # 數據庫配置
    DATABASE_URL: str = "postgresql+asyncpg://user:password@localhost/proxy_db"
    
    # Redis配置
    REDIS_URL: str = "redis://localhost:6379/0"
    REDIS_PASSWORD: Optional[str] = None
    
    # RabbitMQ配置
    CELERY_BROKER_URL: str = "amqp://guest:guest@localhost:5672//"
    CELERY_RESULT_BACKEND: str = "redis://localhost:6379/1"
    
    # 安全配置
    SECRET_KEY: str = "your-secret-key-here"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 7  # 7 days
    ALGORITHM: str = "HS256"
    
    # CORS配置
    ALLOWED_HOSTS: List[str] = ["http://localhost:3000", "http://127.0.0.1:3000"]
    
    # 代理檢查配置
    PROXY_CHECK_TIMEOUT: int = 30
    PROXY_CHECK_MAX_CONCURRENT: int = 50
    PROXY_CHECK_TARGET_URLS: List[str] = [
        "http://httpbin.org/ip",
        "https://httpbin.org/ip",
        "http://icanhazip.com",
        "https://api.ipify.org?format=json"
    ]
    
    # 爬蟲配置
    CRAWLER_MAX_CONCURRENT: int = 10
    CRAWLER_REQUEST_DELAY: float = 1.0
    CRAWLER_USER_AGENT: str = "ProxyCollector/1.0"
    
    # 日誌配置
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # 監控配置
    SENTRY_DSN: Optional[str] = None
    PROMETHEUS_METRICS_PATH: str = "/metrics"
    
    # 緩存配置
    CACHE_TTL: int = 300  # 5 minutes
    CACHE_MAX_SIZE: int = 1000
    
    @validator("DATABASE_URL", pre=True)
    def build_database_url(cls, v: Optional[str]) -> str:
        if v:
            return v
        
        # 從環境變量構建數據庫URL
        user = os.getenv("DB_USER", "proxy_user")
        password = os.getenv("DB_PASSWORD", "proxy_pass")
        host = os.getenv("DB_HOST", "localhost")
        port = os.getenv("DB_PORT", "5432")
        db = os.getenv("DB_NAME", "proxy_db")
        
        return f"postgresql+asyncpg://{user}:{password}@{host}:{port}/{db}"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

# 全局配置實例
settings = Settings()
```

## 8. 錯誤處理與日誌

### 8.1 自定義異常
```python
# app/core/exceptions.py
from fastapi import HTTPException, status
from typing import Optional, Any, Dict

class BusinessException(HTTPException):
    """業務邏輯異常"""
    def __init__(
        self,
        message: str,
        status_code: int = status.HTTP_400_BAD_REQUEST,
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            status_code=status_code,
            detail={
                "message": message,
                "details": details or {}
            }
        )

class NotFoundException(BusinessException):
    """資源未找到異常"""
    def __init__(self, resource: str, identifier: Any):
        super().__init__(
            message=f"{resource} not found",
            status_code=status.HTTP_404_NOT_FOUND,
            details={"resource": resource, "identifier": str(identifier)}
        )

class ValidationException(BusinessException):
    """驗證異常"""
    def __init__(self, message: str, field: Optional[str] = None):
        details = {"field": field} if field else {}
        super().__init__(
            message=message,
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            details=details
        )

class AuthenticationException(BusinessException):
    """認證異常"""
    def __init__(self, message: str = "Authentication failed"):
        super().__init__(
            message=message,
            status_code=status.HTTP_401_UNAUTHORIZED
        )

class AuthorizationException(BusinessException):
    """授權異常"""
    def __init__(self, message: str = "Insufficient permissions"):
        super().__init__(
            message=message,
            status_code=status.HTTP_403_FORBIDDEN
        )

class RateLimitException(BusinessException):
    """速率限制異常"""
    def __init__(self, retry_after: int):
        super().__init__(
            message="Rate limit exceeded",
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            details={"retry_after": retry_after}
        )
```

### 8.2 全局異常處理
```python
# app/core/error_handlers.py
from fastapi import Request, status
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from sqlalchemy.exc import IntegrityError
from redis.exceptions import RedisError
import logging

from app.core.exceptions import BusinessException
from app.core.database import DatabaseException

logger = logging.getLogger(__name__)

async def business_exception_handler(request: Request, exc: BusinessException):
    """業務異常處理"""
    logger.warning(f"Business exception: {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": {
                "type": "business_error",
                "message": exc.detail.get("message"),
                "details": exc.detail.get("details", {})
            }
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """請求驗證異常處理"""
    logger.warning(f"Validation error: {exc.errors()}")
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={
            "success": False,
            "error": {
                "type": "validation_error",
                "message": "Request validation failed",
                "details": exc.errors()
            }
        }
    )

async def database_exception_handler(request: Request, exc: DatabaseException):
    """數據庫異常處理"""
    logger.error(f"Database error: {exc}")
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "success": False,
            "error": {
                "type": "database_error",
                "message": "Database operation failed",
                "details": {"original_error": str(exc)}
            }
        }
    )

async def integrity_error_handler(request: Request, exc: IntegrityError):
    """數據完整性異常處理"""
    logger.error(f"Integrity error: {exc}")
    return JSONResponse(
        status_code=status.HTTP_409_CONFLICT,
        content={
            "success": False,
            "error": {
                "type": "integrity_error",
                "message": "Data integrity violation",
                "details": {"original_error": str(exc.orig) if hasattr(exc, 'orig') else str(exc)}
            }
        }
    )

async def redis_exception_handler(request: Request, exc: RedisError):
    """Redis異常處理"""
    logger.error(f"Redis error: {exc}")
    return JSONResponse(
        status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
        content={
            "success": False,
            "error": {
                "type": "cache_error",
                "message": "Cache service unavailable",
                "details": {"original_error": str(exc)}
            }
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """通用異常處理"""
    logger.error(f"Unexpected error: {exc}", exc_info=True)
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "success": False,
            "error": {
                "type": "internal_error",
                "message": "An unexpected error occurred",
                "details": {}
            }
        }
    )
```

## 9. 監控與健康檢查

### 9.1 健康檢查端點
```python
# app/api/v1/endpoints/health.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from redis import Redis
from app.core.database import get_db
from app.core.cache import get_redis
from app.core.config import settings

router = APIRouter(prefix="/health", tags=["health"])

@router.get("/")
async def health_check(
    db: AsyncSession = Depends(get_db),
    redis: Redis = Depends(get_redis)
):
    """基礎健康檢查"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.APP_VERSION,
        "services": {}
    }
    
    # 檢查數據庫
    try:
        await db.execute("SELECT 1")
        health_status["services"]["database"] = "healthy"
    except Exception as e:
        health_status["services"]["database"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    # 檢查Redis
    try:
        await redis.ping()
        health_status["services"]["redis"] = "healthy"
    except Exception as e:
        health_status["services"]["redis"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    # 檢查RabbitMQ
    try:
        from app.core.celery import celery_app
        i = celery_app.control.inspect()
        active_workers = i.active()
        if active_workers:
            health_status["services"]["rabbitmq"] = "healthy"
        else:
            health_status["services"]["rabbitmq"] = "unhealthy: no active workers"
            health_status["status"] = "unhealthy"
    except Exception as e:
        health_status["services"]["rabbitmq"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    return health_status

@router.get("/ready")
async def readiness_check(
    db: AsyncSession = Depends(get_db),
    redis: Redis = Depends(get_redis)
):
    """就緒檢查"""
    try:
        # 檢查數據庫連接
        await db.execute("SELECT 1")
        
        # 檢查Redis連接
        await redis.ping()
        
        return {"status": "ready", "timestamp": datetime.utcnow().isoformat()}
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Service not ready: {str(e)}")

@router.get("/live")
async def liveness_check():
    """存活檢查"""
    return {"status": "alive", "timestamp": datetime.utcnow().isoformat()}
```

### 9.2 指標收集
```python
# app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from functools import wraps
import time
import logging

logger = logging.getLogger(__name__)

# 請求計數器
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# 請求持續時間
request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

# 活躍代理數量
active_proxy_gauge = Gauge(
    'active_proxies_total',
    'Total number of active proxies',
    ['protocol', 'country', 'anonymity']
)

# 代理檢查計數器
proxy_check_count = Counter(
    'proxy_checks_total',
    'Total number of proxy checks',
    ['protocol', 'result']
)

# 代理檢查持續時間
proxy_check_duration = Histogram(
    'proxy_check_duration_seconds',
    'Proxy check duration in seconds',
    ['protocol']
)

# ETL任務計數器
etl_task_count = Counter(
    'etl_tasks_total',
    'Total number of ETL tasks',
    ['task_type', 'status']
)

# ETL任務持續時間
etl_task_duration = Histogram(
    'etl_task_duration_seconds',
    'ETL task duration in seconds',
    ['task_type']
)

def track_request_duration(method: str, endpoint: str):
    """追蹤請求持續時間的裝飾器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                status_code = 200
                return result
            except Exception as e:
                status_code = getattr(e, 'status_code', 500)
                raise
            finally:
                duration = time.time() - start_time
                request_duration.labels(method=method, endpoint=endpoint).observe(duration)
                request_count.labels(method=method, endpoint=endpoint, status=status_code).inc()
        return wrapper
    return decorator

def track_proxy_check(protocol: str):
    """追蹤代理檢查的裝飾器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                check_result = "success" if result.get("success", False) else "failure"
                return result
            except Exception as e:
                check_result = "error"
                raise
            finally:
                duration = time.time() - start_time
                proxy_check_duration.labels(protocol=protocol).observe(duration)
                proxy_check_count.labels(protocol=protocol, result=check_result).inc()
        return wrapper
    return decorator

def update_proxy_metrics(stats: dict):
    """更新代理指標"""
    try:
        # 更新總數
        for protocol, count in stats.get("by_protocol", {}).items():
            active_proxy_gauge.labels(protocol=protocol, country="all", anonymity="all").set(count)
        
        # 更新國家分布
        for country, count in stats.get("by_country", {}).items():
            active_proxy_gauge.labels(protocol="all", country=country, anonymity="all").set(count)
        
        # 更新匿名等級分布
        for anonymity, count in stats.get("by_anonymity", {}).items():
            active_proxy_gauge.labels(protocol="all", country="all", anonymity=anonymity).set(count)
            
    except Exception as e:
        logger.error(f"Failed to update proxy metrics: {e}")

def get_metrics():
    """獲取Prometheus指標"""
    return generate_latest()
```

這個後端架構規格書提供了完整的企業級後端解決方案，包括微服務架構、數據模型設計、API接口、業務邏輯、異步任務處理、配置管理、錯誤處理、監控和指標收集等。架構支持高可用性、高性能和良好的擴展性。