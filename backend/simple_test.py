#!/usr/bin/env python3
"""
ç°¡åŒ–çš„ä»£ç†IPä¾†æºæ¸¬è©¦è…³æœ¬
"""
import sys
import os
import json
from datetime import datetime

# æ·»åŠ å¾Œç«¯ç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_imports():
    """æ¸¬è©¦å°å…¥æ˜¯å¦æ­£å¸¸"""
    print("ğŸ” æ¸¬è©¦æ¨¡çµ„å°å…¥...")
    
    try:
        from app.etl.extractors.factory import ExtractorFactory
        print("âœ… ExtractorFactory å°å…¥æˆåŠŸ")
        
        factory = ExtractorFactory()
        extractors = factory.get_available_extractors()
        print(f"âœ… å¯ç”¨çˆ¬å–å™¨: {len(extractors)} å€‹")
        for name in extractors:
            print(f"   - {name}")
        
        return True
    except Exception as e:
        print(f"âŒ å°å…¥å¤±æ•—: {e}")
        return False

def test_basic_functionality():
    """æ¸¬è©¦åŸºæœ¬åŠŸèƒ½"""
    print("\nğŸ•·ï¸ æ¸¬è©¦åŸºæœ¬çˆ¬å–åŠŸèƒ½...")
    
    try:
        from app.etl.extractors.factory import ExtractorFactory
        
        factory = ExtractorFactory()
        
        # æ¸¬è©¦å‰µå»ºçˆ¬å–å™¨
        test_extractors = ["free-proxy-list.net", "ssl-proxies"]
        
        for name in test_extractors:
            try:
                if factory.is_extractor_available(name):
                    config = {"base_url": "", "test_mode": True}
                    extractor = factory.create_extractor(name, config)
                    print(f"âœ… {name}: å‰µå»ºæˆåŠŸ")
                else:
                    print(f"âŒ {name}: ä¸å¯ç”¨")
            except Exception as e:
                print(f"âŒ {name}: å‰µå»ºå¤±æ•— - {e}")
        
        return True
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_url_availability():
    """æ¸¬è©¦URLå¯ç”¨æ€§ï¼ˆä½¿ç”¨urllibï¼‰"""
    print("\nğŸ“¡ æ¸¬è©¦URLå¯ç”¨æ€§...")
    
    import urllib.request
    import urllib.error
    
    test_urls = [
        ("89ip.cn", "https://www.89ip.cn/index_1.html"),
        ("å¿«ä»£ç†åœ‹å…§", "https://www.kuaidaili.com/free/intr/"),
        ("Free Proxy List", "https://free-proxy-list.net/"),
        ("SSL Proxies", "https://www.sslproxies.org/"),
    ]
    
    results = []
    
    for name, url in test_urls:
        try:
            req = urllib.request.Request(
                url,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                status_code = response.getcode()
                content_length = len(response.read())
                
                result = {
                    "name": name,
                    "url": url,
                    "status_code": status_code,
                    "success": 200 <= status_code < 300,
                    "content_length": content_length,
                    "timestamp": datetime.now().isoformat()
                }
                results.append(result)
                
                if result["success"]:
                    print(f"âœ… {name}: {status_code} ({content_length} bytes)")
                else:
                    print(f"âŒ {name}: {status_code}")
                    
        except urllib.error.URLError as e:
            result = {
                "name": name,
                "url": url,
                "status_code": None,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            results.append(result)
            print(f"âŒ {name}: {e}")
        except Exception as e:
            result = {
                "name": name,
                "url": url,
                "status_code": None,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            results.append(result)
            print(f"âŒ {name}: {e}")
    
    return results

def generate_report(url_results):
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š ä»£ç†IPä¾†æºæ¸¬è©¦å ±å‘Š")
    print("="*60)
    
    successful_urls = sum(1 for r in url_results if r["success"])
    total_urls = len(url_results)
    
    print(f"\nğŸ“¡ URLå¯ç”¨æ€§æ¸¬è©¦çµæœ:")
    print(f"æˆåŠŸç‡: {successful_urls}/{total_urls} ({successful_urls/total_urls*100:.1f}%)")
    
    print(f"\nè©³ç´°çµæœ:")
    for result in url_results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {result['name']:<20} {result.get('status_code', 'N/A'):<8} {result.get('content_length', 'N/A'):<8} bytes")
        if not result["success"]:
            print(f"    éŒ¯èª¤: {result.get('error', 'Unknown error')}")
    
    # ä¿å­˜å ±å‘Š
    report_data = {
        "test_timestamp": datetime.now().isoformat(),
        "url_results": url_results,
        "summary": {
            "url_success_rate": successful_urls/total_urls*100,
            "total_tested": total_urls,
            "successful": successful_urls
        }
    }
    
    with open("simple_test_report.json", "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: simple_test_report.json")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ä»£ç†IPä¾†æºæ¸¬è©¦...")
    
    # æ¸¬è©¦å°å…¥
    if not test_imports():
        print("âŒ å°å…¥æ¸¬è©¦å¤±æ•—ï¼Œé€€å‡º")
        return
    
    # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
    if not test_basic_functionality():
        print("âŒ åŸºæœ¬åŠŸèƒ½æ¸¬è©¦å¤±æ•—ï¼Œé€€å‡º")
        return
    
    # æ¸¬è©¦URLå¯ç”¨æ€§
    url_results = test_url_availability()
    
    # ç”Ÿæˆå ±å‘Š
    generate_report(url_results)
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
