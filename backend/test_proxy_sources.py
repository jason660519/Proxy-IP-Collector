#!/usr/bin/env python3
"""
ä»£ç†IPä¾†æºå¯ç”¨æ€§æ¸¬è©¦è…³æœ¬
"""
import asyncio
import aiohttp
import json
import time
from datetime import datetime
from typing import Dict, List, Any
import sys
import os

# æ·»åŠ å¾Œç«¯ç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.etl.extractors.factory import ExtractorFactory
from app.core.logging import get_logger

logger = get_logger(__name__)


class ProxySourceTester:
    """ä»£ç†ä¾†æºæ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.session = None
        self.results = {}
        
    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€²å…¥"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        if self.session:
            await self.session.close()
    
    async def test_url_availability(self, url: str, name: str) -> Dict[str, Any]:
        """æ¸¬è©¦URLå¯ç”¨æ€§"""
        try:
            start_time = time.time()
            async with self.session.get(url) as response:
                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
                
                return {
                    "name": name,
                    "url": url,
                    "status_code": response.status,
                    "response_time": round(response_time, 2),
                    "success": 200 <= response.status < 300,
                    "content_length": len(await response.text()) if response.status == 200 else 0,
                    "timestamp": datetime.now().isoformat()
                }
        except asyncio.TimeoutError:
            return {
                "name": name,
                "url": url,
                "status_code": None,
                "response_time": None,
                "success": False,
                "error": "è«‹æ±‚è¶…æ™‚",
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            return {
                "name": name,
                "url": url,
                "status_code": None,
                "response_time": None,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_extractor_functionality(self, extractor_name: str) -> Dict[str, Any]:
        """æ¸¬è©¦çˆ¬å–å™¨åŠŸèƒ½"""
        try:
            factory = ExtractorFactory()
            
            # æª¢æŸ¥çˆ¬å–å™¨æ˜¯å¦å¯ç”¨
            if not factory.is_extractor_available(extractor_name):
                return {
                    "name": extractor_name,
                    "success": False,
                    "error": "çˆ¬å–å™¨ä¸å¯ç”¨",
                    "timestamp": datetime.now().isoformat()
                }
            
            # å‰µå»ºçˆ¬å–å™¨å¯¦ä¾‹
            config = {"base_url": "", "test_mode": True}
            extractor = factory.create_extractor(extractor_name, config)
            
            # åŸ·è¡Œæ¸¬è©¦çˆ¬å–
            start_time = time.time()
            result = await extractor.extract()
            end_time = time.time()
            
            return {
                "name": extractor_name,
                "success": result.success,
                "proxies_found": len(result.proxies),
                "duration": round((end_time - start_time), 2),
                "error_message": result.error_message if hasattr(result, 'error_message') else None,
                "metadata": result.metadata if hasattr(result, 'metadata') else {},
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "name": extractor_name,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }


async def test_proxy_sources():
    """æ¸¬è©¦æ‰€æœ‰ä»£ç†ä¾†æº"""
    print("ğŸ” é–‹å§‹æ¸¬è©¦ä»£ç†IPä¾†æºå¯ç”¨æ€§...")
    
    # å®šç¾©è¦æ¸¬è©¦çš„URL
    test_urls = [
        ("89ip.cn", "https://www.89ip.cn/index_1.html"),
        ("å¿«ä»£ç†åœ‹å…§", "https://www.kuaidaili.com/free/intr/"),
        ("å¿«ä»£ç†æµ·å¤–", "https://www.kuaidaili.com/free/inha/"),
        ("GeoNode API", "https://proxylist.geonode.com/api/proxy-list?limit=10"),
        ("ProxyDB.net", "http://proxydb.net/?offset=0"),
        ("ProxyNova.com", "https://www.proxynova.com/proxy-server-list/"),
        ("Spys.one", "http://spys.one/free-proxy-list/"),
        ("Free Proxy List", "https://free-proxy-list.net/"),
        ("SSL Proxies", "https://www.sslproxies.org/"),
    ]
    
    # å®šç¾©è¦æ¸¬è©¦çš„çˆ¬å–å™¨
    test_extractors = [
        "89ip.cn",
        "kuaidaili-intr", 
        "kuaidaili-inha",
        "geonode-api-v2",
        "proxydb-net",
        "proxynova-com",
        "spys-one",
        "free-proxy-list.net",
        "ssl-proxies"
    ]
    
    async with ProxySourceTester() as tester:
        print("\nğŸ“¡ æ¸¬è©¦URLå¯ç”¨æ€§...")
        url_results = []
        
        # æ¸¬è©¦URLå¯ç”¨æ€§
        for name, url in test_urls:
            print(f"  æ¸¬è©¦ {name}...")
            result = await tester.test_url_availability(url, name)
            url_results.append(result)
            
            if result["success"]:
                print(f"  âœ… {name}: {result['status_code']} ({result['response_time']}ms)")
            else:
                print(f"  âŒ {name}: {result.get('error', 'Unknown error')}")
        
        print("\nğŸ•·ï¸ æ¸¬è©¦çˆ¬å–å™¨åŠŸèƒ½...")
        extractor_results = []
        
        # æ¸¬è©¦çˆ¬å–å™¨åŠŸèƒ½
        for extractor_name in test_extractors:
            print(f"  æ¸¬è©¦ {extractor_name}...")
            result = await tester.test_extractor_functionality(extractor_name)
            extractor_results.append(result)
            
            if result["success"]:
                print(f"  âœ… {extractor_name}: æ‰¾åˆ° {result['proxies_found']} å€‹ä»£ç† ({result['duration']}s)")
            else:
                print(f"  âŒ {extractor_name}: {result.get('error', 'Unknown error')}")
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        generate_test_report(url_results, extractor_results)


def generate_test_report(url_results: List[Dict], extractor_results: List[Dict]):
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š ä»£ç†IPä¾†æºæ¸¬è©¦å ±å‘Š")
    print("="*60)
    
    # URLæ¸¬è©¦çµæœ
    print("\nğŸ“¡ URLå¯ç”¨æ€§æ¸¬è©¦çµæœ:")
    print("-" * 40)
    successful_urls = 0
    for result in url_results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {result['name']:<20} {result.get('status_code', 'N/A'):<8} {result.get('response_time', 'N/A'):<8}ms")
        if result["success"]:
            successful_urls += 1
    
    print(f"\nURLæ¸¬è©¦æˆåŠŸç‡: {successful_urls}/{len(url_results)} ({successful_urls/len(url_results)*100:.1f}%)")
    
    # çˆ¬å–å™¨æ¸¬è©¦çµæœ
    print("\nğŸ•·ï¸ çˆ¬å–å™¨åŠŸèƒ½æ¸¬è©¦çµæœ:")
    print("-" * 40)
    successful_extractors = 0
    total_proxies = 0
    
    for result in extractor_results:
        status = "âœ…" if result["success"] else "âŒ"
        proxies_count = result.get("proxies_found", 0)
        duration = result.get("duration", "N/A")
        print(f"{status} {result['name']:<20} {proxies_count:<8} å€‹ä»£ç† {duration:<8}s")
        if result["success"]:
            successful_extractors += 1
            total_proxies += proxies_count
    
    print(f"\nçˆ¬å–å™¨æ¸¬è©¦æˆåŠŸç‡: {successful_extractors}/{len(extractor_results)} ({successful_extractors/len(extractor_results)*100:.1f}%)")
    print(f"ç¸½è¨ˆæ‰¾åˆ°ä»£ç†: {total_proxies} å€‹")
    
    # è©³ç´°éŒ¯èª¤ä¿¡æ¯
    print("\nâŒ å¤±æ•—è©³æƒ…:")
    print("-" * 40)
    
    for result in url_results + extractor_results:
        if not result["success"]:
            error = result.get("error", result.get("error_message", "Unknown error"))
            print(f"â€¢ {result['name']}: {error}")
    
    # ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶
    report_data = {
        "test_timestamp": datetime.now().isoformat(),
        "url_results": url_results,
        "extractor_results": extractor_results,
        "summary": {
            "url_success_rate": successful_urls/len(url_results)*100,
            "extractor_success_rate": successful_extractors/len(extractor_results)*100,
            "total_proxies_found": total_proxies
        }
    }
    
    with open("proxy_source_test_report.json", "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: proxy_source_test_report.json")


async def main():
    """ä¸»å‡½æ•¸"""
    try:
        await test_proxy_sources()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nğŸ’¥ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
